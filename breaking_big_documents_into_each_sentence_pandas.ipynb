{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "breaking_big_documents_into_each sentence_pandas.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sksoumik/2D-Game-using-Java/blob/master/breaking_big_documents_into_each_sentence_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmbcD0AmTZC7"
      },
      "source": [
        "The following code is used to breaking down big documents into each sentence and making each sentence as a separate row in pandas dataframe, keeping the target values right. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW563PCd4lqS",
        "outputId": "f7a9b7c1-fd7c-4986-9856-1cbbc9c40b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# mount gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ug0Wxi-4oI7"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/nemo/temp_data/harassment_2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb28ZUk-5oaV"
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azLfFToF5p2A"
      },
      "source": [
        "'''\n",
        "My demo dataframe contains three column: Text, Power Harassment, Sexual Harassment\n",
        "\n",
        "Text: contains big paragraphs \n",
        "Power Harassment: Target column (contains 0, 1)\n",
        "Sexual Harassment: Target column (contains 0, 1) \n",
        "\n",
        "\n",
        "We want to keep the Target columns' values to remain same for the individual lines of \n",
        "each paragraph, same as the original ones in big paragraph. \n",
        "'''\n",
        "\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "rows_list = []\n",
        "def splitter(x,nlp):\n",
        "    doc = nlp(x[\"Text\"])\n",
        "    a = [str(sent) for sent in doc.sents]\n",
        "    # a += [x['Text']]\n",
        "    a = [x['Text']] + a\n",
        "    b = len(a)\n",
        "    dictionary = {\"Power Harassment\": np.repeat(x[\"Power Harassment\"],b), \"Sexual Harassment\": np.repeat(x[\"Sexual Harassment\"],b), \"sentence_nr\": list(range(0, b)), \"Text\": a}\n",
        "    dictionaries = [{key : value[i] for key, value in dictionary.items()} for i in range(b)]\n",
        "    for dictionary in dictionaries:\n",
        "        rows_list.append(dictionary)\n",
        "\n",
        "df.apply(lambda x: splitter(x,nlp), axis = 1)\n",
        "new_df = pd.DataFrame(rows_list, columns=['Power Harassment', 'Sexual Harassment', 'sentence_nr','Text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEd607TgLiQH"
      },
      "source": [
        "new_df = new_df[['sentence_nr', 'Text', 'Power Harassment', 'Sexual Harassment']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUG-JgSSHUZF"
      },
      "source": [
        "new_df.to_csv(\"/content/drive/My Drive/nemo/temp_data/harassment_2_qne38.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}